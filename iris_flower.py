# -*- coding: utf-8 -*-
"""IRIS_FLOWER.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bxgWC6b0whniegxEiMRimvgBLlUJ1pnZ

#IRIS FLOWER DATASET
We are woking on the classical iris flower dataset problem.
We took iris flower dataset from kaggle, containing 150 entries with 4 colums.

Each column representing the sepal length, sepal with, petal length, petal width and lastly the species of that particular flower.

Within the 150 entries, the first 50 are of iris-setosa, followed by iris-virginica and iris-vesicolor.
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn import datasets

columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'Class_label']
df = pd.read_csv('IRIS.csv', names=columns)

df

sns.pairplot(df, hue='Class_label')

"""## Analysis
1. Setosa has longest petal width, petal length and sepal length
2. Setosa is easily differential from virginia and versicolor.
3. In terms of sepal width, virginia and versicolor is close with setosa lagging behind the two.

##Separating the data
We have separated the data into 2 columnns, respectively X and Y. With X containing all the numerical vlaues and Y containing the species name
"""

data = df.values
X = data[:,0:4]
Y = data[:,4]

"""##Splitting data into training and testing"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

"""##Model 1-SVC

###Training
"""

from sklearn.svm import SVC
m_svc = SVC()
m_svc.fit(X_train, Y_train)

"""###Testing"""

from sklearn.metrics import accuracy_score
Y_pred1 = m_svc.predict(X_test)
accuracy_score(Y_test, Y_pred1)*100

"""##Model 2-Logistic Regression

###Training
"""

from sklearn.linear_model import LogisticRegression
m_lr = LogisticRegression()
m_lr.fit(X_train, Y_train)

"""###Testing"""

from sklearn.metrics import accuracy_score
Y_pred2 = m_lr.predict(X_test)
accuracy_score(Y_test, Y_pred2)*100

"""##Model 3-Decision Trees"""

from sklearn import tree
m_dtc = tree.DecisionTreeClassifier()
m_dtc = m_dtc.fit(X_train, Y_train)

from sklearn.metrics import accuracy_score
Y_pred3 = m_dtc.predict(X_test)
accuracy_score(Y_test, Y_pred3)*100

"""##Model 4-Random Forest"""

from sklearn.ensemble import RandomForestClassifier
m_rf = RandomForestClassifier(n_estimators=10)
m_rf = m_rf.fit(X, Y)

from sklearn.metrics import accuracy_score
Y_pred4 = m_rf.predict(X_test)
accuracy_score(Y_test, Y_pred4)*100

"""#Report"""

from sklearn.metrics import classification_report
print(classification_report(Y_test, Y_pred1))
print(classification_report(Y_test, Y_pred2))
print(classification_report(Y_test, Y_pred3))
print(classification_report(Y_test, Y_pred4))